{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlyaZutler/Project_2-Trucks/blob/main/DM%20_%20Project_2_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic mitochondria Project - Heavy Machinery Auction Price Estimator\n",
        "\n",
        "> https://www.kaggle.com/t/9baafb8850d74e4499c7b1ba97d6f115\n",
        "\n",
        "### Timeline\n",
        "- **Start Date:** [Start Date]\n",
        "- **End Date:** 14/07/2024 (11 days to go)\n",
        "\n",
        "### 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "Conduct EDA to understand the dataset and identify any data quality issues. Look for missing values, outliers, and relationships between features and the target variable.\n",
        "\n",
        "### 3. Data Preprocessing\n",
        "\n",
        "- Handle missing values appropriately.\n",
        "- Encode categorical variables.\n",
        "- Normalize or standardize numerical features if necessary.\n",
        "\n",
        "### 6. Model Improvement\n",
        "\n",
        "- Handle missing values and categorical variables more effectively.\n",
        "- Use feature importances to identify key features.\n",
        "- Perform feature engineering to create new informative features.\n",
        "- Tune hyperparameters using grid search or other techniques.\n",
        "- Monitor for overfitting by comparing training and testing performance.\n",
        "\n",
        "\n",
        "## Practical Data Science Guidelines\n",
        "\n",
        "- **Efficient Workflows:** Use a random subset of 20,000 rows for initial experiments. Use the full dataset for the final submission.\n",
        "- **Iterative Approach:** Start with a basic model and iteratively improve it by trying small ideas.\n",
        "- **Feature Engineering:** Transform and combine existing features creatively.\n",
        "- **Documentation:** Keep track of your experiments and results. Document what works and what doesn't.\n",
        "\n",
        "## Collaboration and Presentation\n",
        "\n",
        "- **Collaboration:** Discuss your work openly within your team or with other teams. Sharing insights and learning from each other is encouraged.\n",
        "- **Presentation:** Present your methodology, results, and the techniques that helped the most. Document your journey and the steps you took to achieve your results\n",
        "\n"
      ],
      "metadata": {
        "id": "nipVcj4V_QDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
      ],
      "metadata": {
        "id": "ddCt_SZwAXG6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_from_gdrive(url, filename):\n",
        "    # Extract the file ID from the URL\n",
        "    file_id = url.split('/')[-2]\n",
        "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "    # Download the file\n",
        "    if Path(filename).exists():\n",
        "        print(f\"File '{filename}' already exists. Skipping download.\")\n",
        "    else:\n",
        "        gdown.download(download_url, filename, quiet=False)\n",
        "        print(f\"File downloaded as: {filename}\")\n",
        "\n",
        "train = 'https://drive.google.com/file/d/1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5/view?usp=drive_link'\n",
        "valid = 'https://drive.google.com/file/d/1j7x8xhMimKbvW62D-XeDfuRyj9ia636q/view?usp=drive_link'\n",
        "# Example usage\n",
        "\n",
        "download_from_gdrive(train, 'train.csv')\n",
        "download_from_gdrive(valid, 'valid.csv')\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df_valid = pd.read_csv('valid.csv')"
      ],
      "metadata": {
        "id": "2jdlNVVI8s_d",
        "outputId": "a15ff54e-09c2-4333-8611-eb174058c9b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5\n",
            "From (redirected): https://drive.google.com/uc?id=1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5&confirm=t&uuid=473b72ac-4d37-416c-aa02-32f351f1bfe9\n",
            "To: /content/train.csv\n",
            "100%|██████████| 116M/116M [00:02<00:00, 51.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded as: train.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1j7x8xhMimKbvW62D-XeDfuRyj9ia636q\n",
            "To: /content/valid.csv\n",
            "100%|██████████| 3.32M/3.32M [00:00<00:00, 21.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded as: valid.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-861d4f7287ed>:20: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('train.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "dIQ1BlV7wZBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.fiProductClassDesc.value_counts()"
      ],
      "metadata": {
        "id": "30KP0HEQbhrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.info()"
      ],
      "metadata": {
        "id": "pfswzVUcRrUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #df.SalesID.nunique()"
      ],
      "metadata": {
        "id": "SVUG5kuEfcWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.isnull().sum()"
      ],
      "metadata": {
        "id": "lEziG3fNwb-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.describe()"
      ],
      "metadata": {
        "id": "vLqhFjn2R21j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sns.histplot(data=df, x='SalePrice', bins=20)"
      ],
      "metadata": {
        "id": "TCdKm_ok94x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to see value_counts for all categorical columns, but some realy categorical columns has numerical type like ModelID\n",
        "categorical_cols = df.select_dtypes(exclude='number').columns\n",
        "for col in categorical_cols:\n",
        "  print(f\"Value counts for column '{col}':\")\n",
        "  print(df[col].value_counts())\n",
        "  print(f\"NaN values:{df[col].isnull().sum()}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "Zp2RHhayXZWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Data Preprocessing"
      ],
      "metadata": {
        "id": "PhCFYLEqQimv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Num_to_Object(X, col):\n",
        "    for col_ in col:\n",
        "        X[col] = X[col].astype('object')\n",
        "    return X\n",
        "\n",
        "df = Num_to_Object(df, col = ['datasource'])\n",
        "df_valid = Num_to_Object(df_valid, col = ['datasource'])\n"
      ],
      "metadata": {
        "id": "-HtK_91vYq-m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Transmission'] = df['Transmission'].replace('AutoShift', 'Autoshift')\n",
        "def fix_mistakes(X, replacement_dict):\n",
        "\n",
        "    for col, replacements in replacement_dict.items():\n",
        "        X[col] = X[col].replace(replacements)\n",
        "    return X\n",
        "\n",
        "fix_mistakes(df, replacement_dict = {'Transmission': {'AutoShift': 'Autoshift'}})\n",
        "fix_mistakes(df_valid, replacement_dict = {'Transmission': {'AutoShift': 'Autoshift'}})"
      ],
      "metadata": {
        "id": "WSIdpODP2uYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_data(X, date_col):\n",
        "    for col in date_col:\n",
        "        X[col] = pd.to_datetime(X[col])\n",
        "        X[col + '_Year'] = X[col].dt.year\n",
        "        X[col + '_Month'] = X[col].dt.month\n",
        "        X = X.drop(col, axis=1)\n",
        "    return X\n",
        "\n",
        "df = fix_data(df, date_col = ['saledate'])\n",
        "df_valid = fix_data(df_valid, date_col = ['saledate'])"
      ],
      "metadata": {
        "id": "Cnk0uWhQ3bwp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def first_word_name(X, col):\n",
        "    for col_ in col:\n",
        "        X[col_+'_first_word'] = X[col_].apply(lambda x: x.split()[0] if isinstance(x, str) else x)\n",
        "    return X\n",
        "\n",
        "first_word_name(df, col = ['fiProductClassDesc'])\n",
        "first_word_name(df_valid, col = ['fiProductClassDesc'])"
      ],
      "metadata": {
        "id": "7gIXEAiS4lg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ord_encod_nan(X, col, categories):\n",
        "    encoder = OrdinalEncoder(categories=[categories], handle_unknown='use_encoded_value', unknown_value= -1)\n",
        "    X[col + '_3'] = encoder.fit_transform(X[[col]])\n",
        "    X[col + '_3'].replace(-1, np.nan, inplace=True)\n",
        "    X[col + '_3'] = pd.to_numeric(X[col + '_3'], errors='coerce')\n",
        "\n",
        "    return X\n",
        "\n",
        "df = ord_encod_nan(df, col = 'UsageBand', categories = ['Low', 'Medium', 'High'])\n",
        "df_valid = ord_encod_nan(df_valid, col = 'UsageBand', categories = ['Low', 'Medium', 'High'])\n",
        "\n",
        "df = ord_encod_nan(df, col = 'ProductSize', categories = ['Mini', 'Compact', 'Small', 'Medium', 'Large / Medium', 'Large', 'High'])\n",
        "df_valid = ord_encod_nan(df_valid, col = 'ProductSize', categories = ['Mini', 'Compact', 'Small', 'Medium', 'Large / Medium', 'Large', 'High'])"
      ],
      "metadata": {
        "id": "OXUfrZislrnv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_dict(X, col, repl_dict):\n",
        "    new_name = col + '_3'\n",
        "    X[new_name] = X[col]\n",
        "    for old, new in repl_dict.items():\n",
        "        X[new_name] = X[new_name].str.replace(old, new, regex=False)\n",
        "    X[new_name].replace('None or Unspecified', -1)\n",
        "    X[new_name].replace(-1, np.nan, inplace=True)\n",
        "    X[new_name] = pd.to_numeric(X[new_name], errors='coerce')\n",
        "\n",
        "    return X\n",
        "\n",
        "df = replace_dict(df, col = 'Undercarriage_Pad_Width', repl_dict= {' inch': ''})\n",
        "df_valid = replace_dict(df_valid, col= 'Undercarriage_Pad_Width', repl_dict = {' inch': ''})\n",
        "\n",
        "df = replace_dict(df, col = 'Stick_Length', repl_dict= {\"' \": '.', '\"': ''})\n",
        "df_valid = replace_dict(df_valid, col= 'Stick_Length', repl_dict = {\"' \": '.', '\"': ''})"
      ],
      "metadata": {
        "id": "unmZNUg5AE6S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New fichers (depending by df split)"
      ],
      "metadata": {
        "id": "kEgLffREEq9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df[df['YearMade'] == 1000].head(20) # i have not idias what to do with year 1000"
      ],
      "metadata": {
        "id": "oEEe-qSaHyHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean / Target coding"
      ],
      "metadata": {
        "id": "zmFxzf7MFOTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_target_mean_dict(X, target_col):\n",
        "    target_mean_dict = {}\n",
        "    target_nan_mean_dict = {}\n",
        "\n",
        "    for col in df.select_dtypes(exclude='number').columns:\n",
        "        target_mean_dict[col] = X.groupby(col)[target_col].mean().to_dict()\n",
        "        target_nan_mean_dict[col] = X[df[col].isna()][target_col].mean()\n",
        "\n",
        "    return target_mean_dict, target_nan_mean_dict\n",
        "\n",
        "target_mean_dict, target_nan_mean_dict = make_target_mean_dict(df, target_col = 'SalePrice')\n",
        "\n",
        "def target_encode(X, target_mean_dict, target_nan_mean_dict):\n",
        "    for col in X.select_dtypes(exclude='number').columns:\n",
        "        X[col + '_2'] = X[col].map(target_mean_dict[col]).fillna(target_nan_mean_dict[col])\n",
        "        X[col + '_2'] = X[col + '_2'].astype(float)\n",
        "    return X\n",
        "\n",
        "df = target_encode(df, target_mean_dict, target_nan_mean_dict)\n",
        "df_valid = target_encode(df_valid, target_mean_dict, target_nan_mean_dict)"
      ],
      "metadata": {
        "id": "yEsroVcqEqio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select data for model"
      ],
      "metadata": {
        "id": "GqOepCDgRE4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select_dtypes('number')\n",
        "X_valid = df_valid.select_dtypes('number')\n",
        "\n",
        "y = df['SalePrice']\n",
        "X = df.drop(columns=['SalePrice', 'MachineID', 'ModelID', 'SalesID'])\n",
        "X_valid = X_valid.drop(columns=['MachineID', 'ModelID', 'SalesID'])"
      ],
      "metadata": {
        "id": "A2rncyq9T5qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(20, 20))\n",
        "# sns.heatmap(X.corr(), vmin=-1, fmt=\".1f\", vmax=1, annot=True, cmap='BrBG')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "afhKgZflUIDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train_test_split"
      ],
      "metadata": {
        "id": "73Gx2EJ3IrDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X.sample(30000, random_state=42)\n",
        "y_train = y.loc[X_train.index]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "# X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "# X_valid2 = pd.DataFrame(scaler.transform(X_valid2), columns=X_valid2.columns, index=X_valid2.index)\n",
        "\n",
        "X_train = X_train.fillna(X_train.mean())\n",
        "X_test = X_test.fillna(X_train.mean())\n",
        "X_valid = X_valid.fillna(X_train.mean())"
      ],
      "metadata": {
        "id": "1wW25fcaG-5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model = RandomForestRegressor(n_jobs=-1,\n",
        "                              n_estimators = 700,\n",
        "                              #max_depth = 10,\n",
        "                              min_impurity_decrease = 10,\n",
        "                              random_state = 42,\n",
        "                              max_features = 'sqrt',\n",
        "                              #max_samples=0.75\n",
        "                              )\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "y_valid_pred = model.predict(X_valid)\n",
        "\n",
        "print(f'Train RMSE:', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
        "print(f'Test RMSE:', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
        "print(f'R²:' , r2_score(y_test, y_test_pred))\n",
        "print(f'Train MAE:', mean_absolute_error(y_train, y_train_pred))\n",
        "print(f'Test MAE:', mean_absolute_error(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "id": "XCqjoGIAMQRp",
        "outputId": "9727f208-8c4f-451a-f8c9-b7d5b2c730c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 3791.6000972295774\n",
            "Train MAE: 2576.7964623446896\n",
            "CPU times: user 14min 11s, sys: 8.82 s, total: 14min 20s\n",
            "Wall time: 8min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Feature importance\n",
        "pd.Series(\n",
        "    model.feature_importances_,\n",
        "    index=model.feature_names_in_\n",
        ").sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "jcMpXIs0PO_m",
        "outputId": "9386768d-24dc-49d6-a006-0e16c2716eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fiModelDesc_2                      0.292358\n",
              "fiBaseModel_2                      0.104009\n",
              "fiProductClassDesc_2               0.083600\n",
              "YearMade                           0.083561\n",
              "saledate_Year                      0.059312\n",
              "Enclosure_2                        0.053806\n",
              "fiSecondaryDesc_2                  0.050498\n",
              "ProductSize_2                      0.033550\n",
              "state_2                            0.018536\n",
              "fiModelDescriptor_2                0.017398\n",
              "fiProductClassDesc_first_word_2    0.017108\n",
              "saledate_Month                     0.016775\n",
              "ProductGroupDesc_2                 0.016284\n",
              "ProductGroup_2                     0.014976\n",
              "MachineHoursCurrentMeter           0.012377\n",
              "auctioneerID                       0.011468\n",
              "datasource_2                       0.008987\n",
              "Ripper_2                           0.007140\n",
              "Hydraulics_2                       0.006955\n",
              "fiModelSeries_2                    0.006494\n",
              "Tire_Size_2                        0.005989\n",
              "Blade_Type_2                       0.005690\n",
              "Coupler_System_2                   0.005527\n",
              "Hydraulics_Flow_2                  0.005323\n",
              "UsageBand_2                        0.004943\n",
              "Grouser_Tracks_2                   0.004617\n",
              "Forks_2                            0.004136\n",
              "Stick_Length_2                     0.003580\n",
              "Enclosure_Type_2                   0.003292\n",
              "Travel_Controls_2                  0.003270\n",
              "Drive_System_2                     0.002907\n",
              "Pushblock_2                        0.002899\n",
              "Blade_Width_2                      0.002896\n",
              "Transmission_2                     0.002877\n",
              "Undercarriage_Pad_Width_2          0.002686\n",
              "Ride_Control_2                     0.002546\n",
              "Coupler_2                          0.002519\n",
              "Track_Type_2                       0.002329\n",
              "Engine_Horsepower_2                0.002090\n",
              "Thumb_2                            0.002024\n",
              "Grouser_Type_2                     0.001800\n",
              "Scarifier_2                        0.001778\n",
              "Tip_Control_2                      0.001676\n",
              "Pattern_Changer_2                  0.001583\n",
              "Blade_Extension_2                  0.001313\n",
              "Pad_Type_2                         0.000976\n",
              "Stick_2                            0.000879\n",
              "Backhoe_Mounting_2                 0.000745\n",
              "Steering_Controls_2                0.000721\n",
              "Differential_Type_2                0.000636\n",
              "Turbocharged_2                     0.000560\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a submission file\n",
        "submission = pd.DataFrame({'SalesID': X_valid['SalesID'], 'SalePrice': y_valid_pred})\n",
        "submission.to_csv('final_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "P5NywMhp16nq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}